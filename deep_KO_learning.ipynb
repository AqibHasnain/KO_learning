{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "print(\"Using PyTorch Version %s\" %torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Datasets ###\n",
    "\n",
    "dataset = 5 # each dataset contains the global snapshot matrix as well as the number of snapshots per trajectory and the number of trajectories\n",
    "\n",
    "# add new datasets as below\n",
    "if dataset == 0: \n",
    "    file_dir = 'toggle_switch_data.p'\n",
    "    \n",
    "if dataset == 1: \n",
    "    file_dir = 'toggle_switch_data_normed.p'\n",
    "    \n",
    "if dataset == 2: \n",
    "    file_dir = 'stable_linsys.p'\n",
    "    \n",
    "if dataset == 3:\n",
    "    file_dir = 'slow_manifold_data.p'\n",
    "    \n",
    "if dataset == 4: \n",
    "    file_dir = 'slow_manifold_data_normed.p'\n",
    "    \n",
    "if dataset == 5:\n",
    "    file_dir = 'malathion_polyculture_pfluorescens_TPMs.p'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snapshot_matrices(X,nT,nTraj): \n",
    "    '''This function assumes the global snapshot matrix is constructed with trajectories sequentially placed in the columns'''\n",
    "    prevInds = [x for x in range(0,nT-1)]\n",
    "    forInds = [x for x in range(1,nT)]\n",
    "    for i in range(0,nTraj-1):\n",
    "        if i == 0:\n",
    "            more_prevInds = [x + nT for x in prevInds]\n",
    "            more_forInds = [x + nT for x in forInds]\n",
    "        else: \n",
    "            more_prevInds = [x + nT for x in more_prevInds]\n",
    "            more_forInds = [x + nT for x in more_forInds]\n",
    "        prevInds = prevInds + more_prevInds\n",
    "        forInds = forInds + more_forInds\n",
    "    Xp = X[:,prevInds]\n",
    "    Xf = X[:,forInds]\n",
    "    return Xp,Xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,nT,nTraj = pickle.load(open(data_path+file_dir,'rb'))\n",
    "Xp,Xf = get_snapshot_matrices(X,nT,nTraj)\n",
    "trainXp = torch.Tensor(Xp.T)\n",
    "trainXf = torch.Tensor(Xf.T)\n",
    "testX = torch.Tensor(X.T)\n",
    "\n",
    "print('Dimension of the state: ' + str(trainXp.shape[1]));\n",
    "print('Number of trajectories: ' + str(nTraj));\n",
    "print('Number of total snapshots: ' + str(nT*nTraj));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neural network parameters ###\n",
    "\n",
    "NUM_INPUTS = trainXp.shape[1] # dimension of input\n",
    "NUM_HL = 8 # number of hidden layers (excludes the input and output layers)\n",
    "NODES_HL = 8 # number of nodes per hidden layer (number of learned observables)\n",
    "HL_SIZES = [NODES_HL for i in range(0,NUM_HL+1)] \n",
    "NUM_OUTPUTS = NUM_INPUTS + HL_SIZES[-1] + 1 # output layer takes in dimension of input + 1 + dimension of hl's\n",
    "BATCH_SIZE = 2 #int(nT/10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hl_sizes):\n",
    "        super(Net, self).__init__()\n",
    "        current_dim = input_dim\n",
    "        self.linears = nn.ModuleList()\n",
    "        for hl_dim in hl_sizes:\n",
    "            self.linears.append(nn.Linear(current_dim, hl_dim))\n",
    "            current_dim = hl_dim\n",
    "        self.linears.append(nn.Linear(output_dim, output_dim,bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_vecs = x\n",
    "        for layer in self.linears[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        y = torch.cat((torch.Tensor(np.ones((x.shape[0],1))),input_vecs,x),dim=1)\n",
    "        x = self.linears[-1](y)\n",
    "        return {'KPsiXp':x,'PsiXf':y} \n",
    "\n",
    "net = Net(NUM_INPUTS,NUM_OUTPUTS,HL_SIZES)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function and the optimizer\n",
    "\n",
    "LEARNING_RATE = 0.05\n",
    "L2_REG = 0.0\n",
    "MOMENTUM = 0.00\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=LEARNING_RATE,momentum=MOMENTUM,weight_decay=L2_REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the network \n",
    "print_less_often = 200\n",
    "eps = 1e-100\n",
    "train_loss = []\n",
    "maxEpochs = 100000\n",
    "prev_loss = 0\n",
    "curr_loss = 1e10\n",
    "epoch = 0\n",
    "numDatapoints = nT*nTraj\n",
    "net.train()\n",
    "while (epoch <= maxEpochs): # and (np.abs(curr_loss-prev_loss) > eps):\n",
    "    prev_loss = curr_loss\n",
    "    for i in range(0,trainXp.shape[0],BATCH_SIZE):\n",
    "        \n",
    "        Kpsixp = net(trainXp[i:i+BATCH_SIZE])['KPsiXp'] \n",
    "        psixf = net(trainXf[i:i+BATCH_SIZE])['PsiXf']\n",
    "        loss = loss_func(psixf, Kpsixp)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    curr_loss = loss.item()\n",
    "    if epoch % print_less_often == 0:\n",
    "        print('['+str(epoch)+']'+' loss = '+str(loss.item()))\n",
    "        train_loss.append(loss.item()) \n",
    "    epoch+=1\n",
    "print('['+str(epoch)+']'+' loss = '+ str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = net.linears[-1].weight[:].detach().numpy()\n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quick test\n",
    "\n",
    "Kpsixp_test = net(testXp[nT-2:nT-1])['KPsiXp']\n",
    "psixf_test = net(testXf[nT-2:nT-1])['PsiXf']\n",
    "print(Kpsixp_test)\n",
    "print(psixf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PsiX_test = net(testX)['PsiXf']\n",
    "PsiX_test = PsiX_test.detach().numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "\n",
    "numStates = data.shape[0]\n",
    "traj = 4 #np.random.randint(0,nTraj) # np.random.randint(0,nTraj/2)\n",
    "init_index = traj*(nT)\n",
    "\n",
    "predHorizon = nT\n",
    "PsiX_pred = np.zeros((K.shape[0],predHorizon))\n",
    "for i in range(0,predHorizon):\n",
    "    PsiX_pred[:,i:i+1] = np.dot(np.linalg.matrix_power(K,i),PsiX_test[:,init_index:init_index+1]) \n",
    "\n",
    "mse = np.linalg.norm(PsiX_test[:,init_index:init_index+predHorizon] - PsiX_pred,'fro')/np.linalg.norm(PsiX_test[:,init_index:init_index+predHorizon],'fro')\n",
    "print('Trajectory ' + str(traj) + ', MSE: ' + str(round(mse,5)))\n",
    "\n",
    "if numStates > 20: # just for plotting\n",
    "    numPlots = 20\n",
    "    plotStates = np.random.randint(1,numStates-1,numPlots)\n",
    "for i in plotStates:\n",
    "    plt.figure();\n",
    "    plt.plot(PsiX_test[i,init_index:init_index+predHorizon],'.-',ms=10,lw=3,color='tab:blue');\n",
    "    plt.plot(PsiX_pred[i,0:predHorizon],'.--',ms=10,lw=3,color='tab:orange');\n",
    "#     plt.ylim([-1,1])\n",
    "    plt.ylabel(r'$\\mathbf{x}$'+str(i))\n",
    "    plt.legend(handles=[truthLeg,predLeg]);\n",
    "truthLeg = mlines.Line2D([], [], color='black',linestyle='-',marker='',label='Truth')\n",
    "predLeg = mlines.Line2D([], [], color='black',linestyle='--',label='Predicted')\n",
    "# plt.savefig('repr_preds_traj'+str(traj)+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### A better prediction calculation ###\n",
    "\n",
    "PsiX_pred = np.zeros((K.shape[0],numDatapoints))\n",
    "trajInds = [x for x in range(0,nT)]\n",
    "trajInds = [trajInds for x in range(0,nTraj)]\n",
    "trajInds = [j for i in trajInds for j in i] \n",
    "count = 0\n",
    "initInd = 0\n",
    "for i in range(0,nTraj):\n",
    "    psix_test_ic = PsiX_test[:,i*nT:i*nT+1]\n",
    "    for j in range(0,nT):\n",
    "        PsiX_pred[:,count:count+1] = np.dot(np.linalg.matrix_power(K,j),psix_test_ic)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### storing the mean squared errors for each gene (row) ###\n",
    "per_gene_mse = []\n",
    "for k in range(1,trainData.shape[1]+1):\n",
    "    dist = np.linalg.norm(PsiX_pred[k,:] -PsiX_test[k,:],ord=2)/np.linalg.norm(PsiX_test[k,:],ord=2)\n",
    "    if np.isinf(dist):\n",
    "        dist = 0\n",
    "    per_gene_mse.append(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mu = np.mean(X,axis=1)\n",
    "# plt.figure();\n",
    "# plt.plot(per_gene_mse);\n",
    "# plt.plot(np.abs(total_mu));\n",
    "\n",
    "fig, ax1 = plt.subplots();\n",
    "left, bottom, width, height = [0.65, 0.6, 0.2, 0.2]\n",
    "ax2 = fig.add_axes([left, bottom, width, height]);\n",
    "ax1.plot(per_gene_mse);\n",
    "ax1.plot(np.abs(total_mu));\n",
    "ax2.plot(per_gene_mse);\n",
    "# ax2.plot(np.abs(total_mu));\n",
    "# ax2.set_xlim([80,120]);\n",
    "ax2.set_ylim([0.00005,0.0006]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.dot(PsiX_pred,PsiX_test.T)\n",
    "plt.figure(figsize=(7,5));\n",
    "sn.heatmap(corr[1:123,1:123],cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "theta = np.linspace(0,2*math.pi,100)\n",
    "plt.figure(figsize=(6,5));\n",
    "plt.plot(np.real(np.linalg.eigvals(K)),np.imag(np.linalg.eigvals(K)),'o',ms=10);\n",
    "plt.plot(np.cos(theta),np.sin(theta),color='black');\n",
    "plt.ylabel('$Imag(\\lambda)$');\n",
    "plt.xlabel('$Real(\\lambda)$');\n",
    "plt.axis('equal');\n",
    "# plt.savefig('toggleswitch_eigvals.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
