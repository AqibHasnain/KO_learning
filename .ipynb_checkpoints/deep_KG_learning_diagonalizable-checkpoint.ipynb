{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hl_sizes):\n",
    "        super(Net, self).__init__()\n",
    "        current_dim = input_dim\n",
    "        self.linears = nn.ModuleList()\n",
    "        for hl_dim in hl_sizes:\n",
    "            self.linears.append(nn.Linear(current_dim, hl_dim))\n",
    "            current_dim = hl_dim\n",
    "        self.L = nn.Parameter(torch.rand(output_dim,requires_grad=True)) # vector of eigenvalues\n",
    "        self.V = nn.Parameter(torch.rand(output_dim,output_dim,requires_grad=True)) # matrix of eigenvecs\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_vecs = x\n",
    "        for layer in self.linears:\n",
    "            x = F.relu(layer(x))\n",
    "        x = torch.cat((torch.Tensor(np.ones((x.shape[0],1))),input_vecs,x),dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.dirname('deep_KO_learning.py') # getting relative path\n",
    "trained_models_path = os.path.join(script_dir, 'trained_models') # which relative path do you want to see\n",
    "data_path = os.path.join(script_dir,'data/')\n",
    "\n",
    "file_dir = 'toggle_switch_data_normed.p'\n",
    "\n",
    "def get_snapshot_matrices(X,nT,nTraj): \n",
    "        '''This function assumes the global snapshot matrix is constructed with trajectories \n",
    "            sequentially placed in the columns'''\n",
    "        prevInds = [x for x in range(0,nT-1)]\n",
    "        forInds = [x for x in range(1,nT)]\n",
    "        for i in range(0,nTraj-1):\n",
    "            if i == 0:\n",
    "                more_prevInds = [x + nT for x in prevInds]\n",
    "                more_forInds = [x + nT for x in forInds]\n",
    "            else: \n",
    "                more_prevInds = [x + nT for x in more_prevInds]\n",
    "                more_forInds = [x + nT for x in more_forInds]\n",
    "            prevInds = prevInds + more_prevInds\n",
    "            forInds = forInds + more_forInds\n",
    "        Xp = X[:,prevInds]\n",
    "        Xf = X[:,forInds]\n",
    "        return Xp,Xf\n",
    "    \n",
    "X,nT,nTraj,dt_list = pickle.load(open(data_path+file_dir,'rb'))\n",
    "Xp,Xf = get_snapshot_matrices(X,nT,nTraj)\n",
    "trainXp = torch.Tensor(Xp.T)\n",
    "trainXf = torch.Tensor(Xf.T)\n",
    "testX = torch.Tensor(X.T)\n",
    "\n",
    "numDatapoints = nT*nTraj # number of total snapshots\n",
    "\n",
    "print('Dimension of the state: ' + str(trainXp.shape[1]));\n",
    "print('Number of trajectories: ' + str(nTraj));\n",
    "print('Number of total snapshots: ' + str(nT*nTraj));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INPUTS = trainXp.shape[1] # dimension of input\n",
    "NUM_HL = 6 # number of hidden layers (excludes the input layer)\n",
    "NODES_HL = 6 # number of nodes per hidden layer (number of learned observables)\n",
    "HL_SIZES = [NODES_HL for i in range(0,NUM_HL+1)] \n",
    "NUM_OUTPUTS = NUM_INPUTS + HL_SIZES[-1] + 1 # output layer takes in dimension of input + 1 + dimension of hl's\n",
    "\n",
    "net = Net(NUM_INPUTS,NUM_OUTPUTS,HL_SIZES)\n",
    "print(net)\n",
    "# print(list(net.named_parameters())) # or list(net.parameters()) if you don't need to view the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the loss function and the optimizer ###\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "L2_REG = 0.0\n",
    "MOMENTUM = 0.0\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=LEARNING_RATE,momentum=MOMENTUM,weight_decay=L2_REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Training the network ###\n",
    "print_less_often = 2\n",
    "lr_update = 50\n",
    "lr_stop_update = 51\n",
    "eps = 1e-13\n",
    "train_loss = []\n",
    "maxEpochs = 20000\n",
    "prev_loss = 0\n",
    "curr_loss = 1e10\n",
    "epoch = 0\n",
    "net.train()\n",
    "\n",
    "\n",
    "while (epoch <= maxEpochs): \n",
    "\n",
    "    if epoch % print_less_often == 0:\n",
    "        if np.abs(prev_loss - curr_loss) < eps:\n",
    "            break\n",
    "        prev_loss = curr_loss\n",
    "\n",
    "    for i in range(0,trainXp.shape[0]):\n",
    "        \n",
    "        dt = dt_list[i]\n",
    "        \n",
    "        eL = torch.diag_embed(torch.exp(net.L*dt)) # exponential of the eigs, then embedded into a diagonal matrix\n",
    "        K = torch.matmul(torch.matmul(net.V,eL),torch.pinverse(net.V)) # matrix representation of Koopman operator\n",
    "        \n",
    "        Kpsixp = torch.matmul(net(trainXp[i:i+1]),K) \n",
    "        psixf = net(trainXf[i:i+1])\n",
    "        loss = loss_func(psixf, Kpsixp)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    curr_loss = loss.item()\n",
    "\n",
    "    if epoch % print_less_often == 0:\n",
    "        print('['+str(epoch)+']'+' loss = '+str(loss.item()))\n",
    "        \n",
    "    train_loss.append(loss.item()) \n",
    "    epoch+=1\n",
    "    \n",
    "#     if epoch % lr_update == 0:\n",
    "#         if epoch < lr_stop_update:\n",
    "#             for g in optimizer.param_groups:\n",
    "#                 g['lr'] = LEARNING_RATE * 0.1\n",
    "#             LEARNING_RATE = g['lr']\n",
    "\n",
    "\n",
    "train_loss.append(loss.item())\n",
    "print('['+str(epoch)+']'+' loss = '+ str(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':14});\n",
    "plt.semilogy(train_loss,lw=4);\n",
    "plt.ylabel('MSE Loss');\n",
    "plt.xlabel('Epoch');\n",
    "# plt.savefig('Loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([NUM_INPUTS,NUM_OUTPUTS,HL_SIZES],open(trained_models_path+'/KG_toggleSwitch_netsize.pickle','wb'))\n",
    "torch.save(net.state_dict(), trained_models_path+'/KG_toggleSwitch_net.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
